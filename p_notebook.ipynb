{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "---------All packages are imported--------------\n"
    }
   ],
   "source": [
    "# Import packages ....\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from bullet import Bullet, Check, YesNo, Input, SlidePrompt\n",
    "from bullet import colors\n",
    "import datetime\n",
    "import csv\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import ipywidgets as widgets\n",
    "print(\"---------All packages are imported--------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='model_noun', description='model_noun:', placeholder='Type model_noun')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a5de478d755432694c7752abb7e7e23"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='./Dataset', description='path:', placeholder='Type the path')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb2cfd87d38e41ba8c113a74a4458450"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "IntText(value=128, description='batch_size :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38d31b9f68124d4ba69f0643029feb40"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "IntText(value=10, description='epochs :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "820eca6df8a549aa90d72b049f63159f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.2, description='dropout1 :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52e475b5e4c0422bbf4d7657fc7510fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.2, description='dropout2 :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1839cab62f4648d08274211a2de693bf"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='adam', description='optimizer:', placeholder='Type the optimizer')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42af52775c3e43639691a121723496b2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.001, description='learningrate :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ba5f816835d4cf4b7ffe6b096a22265"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.001, description='momentum :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04c920edf5d74e38a982f139c8ed73c9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.0, description='rho :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a457e37d389b4d018d8094c6e64d6316"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.9, description='beta1 :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "706813df3d36459ab543681f99c94dd3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "FloatText(value=0.9, description='beta2 :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "455a260120d247b4b321e96c83ad444e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='False', description='T or F:', placeholder='Type True or False')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b210408aba44e74bae15a49a495322d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Text(value='False', description='T or F:', placeholder='Type True or False')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4592384d60c04daf99571a2478b45a3f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "IntText(value=10, description='Kfold :')",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1db81457e07f443888c1e269b62634a5"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "model_nom = widgets.Text(\n",
    "    value='model_noun',\n",
    "    placeholder='Type model_noun',\n",
    "    description='model_noun:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "path = widgets.Text(\n",
    "    value='./Dataset',\n",
    "    placeholder='Type the path',\n",
    "    description='path:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "batch_size = widgets.IntText(\n",
    "        value=128,\n",
    "        description='batch_size :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "epochs = widgets.IntText(\n",
    "        value=10,\n",
    "        description='epochs :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "dropout1 = widgets.FloatText(\n",
    "        value=0.2,\n",
    "        description='dropout1 :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "dropout2 = widgets.FloatText(\n",
    "        value=0.2,\n",
    "        description='dropout2 :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "optimizer = widgets.Text(\n",
    "    value='adam',\n",
    "    placeholder='Type the optimizer',\n",
    "    description='optimizer:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "learningrate = widgets.FloatText(\n",
    "        value=0.001,\n",
    "        description='learningrate :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "momentum = widgets.FloatText(\n",
    "        value=0.001,\n",
    "        description='momentum :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "rho = widgets.FloatText(\n",
    "        value=0.0,\n",
    "        description='rho :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "beta1 = widgets.FloatText(\n",
    "        value=0.9,\n",
    "        description='beta1 :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "beta2 = widgets.FloatText(\n",
    "        value=0.9,\n",
    "        description='beta2 :',\n",
    "        disabled=False\n",
    ")\n",
    "\n",
    "nesterov = widgets.Text(\n",
    "    value='False',\n",
    "    placeholder='Type True or False',\n",
    "    description='T or F:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "amsgrad = widgets.Text(\n",
    "    value='False',\n",
    "    placeholder='Type True or False',\n",
    "    description='T or F:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "Kfold = widgets.IntText(\n",
    "        value=10,\n",
    "        description='Kfold :',\n",
    "        disabled=False\n",
    ")\n",
    "display(model_nom)\n",
    "display(path)\n",
    "display(batch_size)\n",
    "display(epochs)\n",
    "display(dropout1)\n",
    "display(dropout2)\n",
    "display(optimizer)\n",
    "display(learningrate)\n",
    "display(momentum)\n",
    "display(rho)\n",
    "display(beta1)\n",
    "display(beta2)\n",
    "display(nesterov)\n",
    "display(amsgrad)\n",
    "display(Kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split=Kfold.value\n",
    "epochs=epochs.value\n",
    "model_nom = model_nom.value\n",
    "pathData = path.value\n",
    "optimizer = optimizer.value\n",
    "dropout1 = dropout1.value\n",
    "dropout2 = dropout2.value\n",
    "batch_size = batch_size.value\n",
    "learningrate = learningrate.value\n",
    "momentum = bool(momentum.value)\n",
    "nesterov = bool(nesterov.value)\n",
    "beta1 = beta1.value\n",
    "beta2 = beta2.value\n",
    "amsgrad = amsgrad.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder of logs including models in orther to visualize them with tensorboard tool\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(model_nom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create path data\n",
    "PATH = os.path.join(pathData)\n",
    "\n",
    "# define training and validation paths\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "# create a list 'train' containing paths to every class in train folder\n",
    "train = []\n",
    "for i in range(len(os.listdir(train_dir))):\n",
    "    # directory with our training pictures\n",
    "    train += [os.path.join(train_dir, os.listdir(train_dir)[i])]\n",
    "    train = sorted(train)\n",
    "\n",
    "# create a list 'validation' containing paths to every class in validation folder\n",
    "validation = []\n",
    "for i in range(len(os.listdir(validation_dir))):\n",
    "    # directory with our validation pictures\n",
    "    validation += [os.path.join(validation_dir,\n",
    "                                os.listdir(validation_dir)[i])]\n",
    "    validation = sorted(validation)\n",
    "\n",
    "# Understand the data\n",
    "total_train = 0\n",
    "for i in range(len(os.listdir(train_dir))):\n",
    "    # total_train = total number of images in all classes in train folder\n",
    "    total_train += len(os.listdir(train[i]))\n",
    "\n",
    "total_val = 0\n",
    "for i in range(len(os.listdir(validation_dir))):\n",
    "    # total_val =total number of images in all classes in validation folder\n",
    "    total_val += len(os.listdir(validation[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define attributes\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150\n",
    "RGB_channels = 3  # three colors: Red,Green & Blue\n",
    "filters_for_CONV1 = 16  # the number of output filters in the convolution 1\n",
    "filters_for_CONV2 = 32  # the number of output filters in the convolution 2\n",
    "filters_for_CONV3 = 64  # the number of output filters in the convolution 3\n",
    "Kernel_SIZE = 3  # An integer or tuple/list of 2 integers,\n",
    "# specifying the height and width of the 2D convolution window.\n",
    "# Can be a single integer to specify the same value for all spatial dimensions.\n",
    "units1 = 512  # Positive integer, dimensionality of the output space\n",
    "units2 = len(os.listdir(train_dir))\n",
    "units3 = dropout1\n",
    "units4 = dropout2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Generator for our training data\n",
    "train_image_generator = ImageDataGenerator(rescale=1. / 255,\n",
    "                                           rotation_range=45,\n",
    "                                           width_shift_range=.15,\n",
    "                                           height_shift_range=.15,\n",
    "                                           horizontal_flip=True,\n",
    "                                           zoom_range=0.5)\n",
    "\n",
    "# Generator for our validation data\n",
    "validation_image_generator = ImageDataGenerator(\n",
    "    rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2480 images belonging to 10 classes.\nFound 100 images belonging to 10 classes.\n"
    }
   ],
   "source": [
    "#  read the images from train folder\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(\n",
    "                                                               IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='categorical')\n",
    "\n",
    "#  read the images from validation folder\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(\n",
    "                                                                  IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When using any layer as the first layer in a model,\n",
    "# provide the keyword argument input_shape (tuple of integers,\n",
    "# does not include the sample axis), e.g. input_shape=(128, 128, 3)\n",
    "# for 128x128 RGB pictures in data_format=\"channels_last\".\n",
    "\n",
    "# define convolutions & fully connected layers\n",
    "model = Sequential([\n",
    "    Conv2D(filters_for_CONV1, Kernel_SIZE, padding='same',\n",
    "           activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, RGB_channels)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters_for_CONV2, Kernel_SIZE, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(filters_for_CONV3, Kernel_SIZE, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dropout(units3),\n",
    "    Dense(units1, activation='relu'),\n",
    "    Dropout(units4),\n",
    "    Dense(units2, activation='softmax')\n",
    "])\n",
    "\n",
    "# switch beteween different optimizers\n",
    "if optimizer == 'sgd':\n",
    "    dynamic_optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=learningrate, momentum=momentum, nesterov=nesterov)\n",
    "elif optimizer == 'rmsprop':\n",
    "    dynamic_optimizer = tf.keras.optimizers.RMSprop(learning_rate=learningrate)\n",
    "elif optimizer == 'adagrad':\n",
    "    dynamic_optimizer = tf.keras.optimizers.Adagrad(learning_rate=learningrate)\n",
    "elif optimizer == 'adadelta':\n",
    "    dynamic_optimizer = tf.keras.optimizers.Adadelta(\n",
    "        learning_rate=learningrate)\n",
    "elif optimizer == 'adamax':\n",
    "    dynamic_optimizer = tf.keras.optimizers.Adamax(\n",
    "        learning_rate=learningrate, beta_1=beta1, beta_2=beta2)\n",
    "elif optimizer == 'nadam':\n",
    "    dynamic_optimizer = tf.keras.optimizers.Nadam(\n",
    "        learning_rate=learningrate, beta_1=beta1, beta_2=beta2)\n",
    "else:  # Adam\n",
    "    dynamic_optimizer = tf.keras.optimizers.Adam(\n",
    "        learning_rate=learningrate, beta_1=beta1, beta_2=beta2, amsgrad=amsgrad)\n",
    "\n",
    "# build a model architecture with CNN\n",
    "model.compile(optimizer=dynamic_optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize Model\n",
    "# Keras provides a way to summarize a model.\n",
    "# The summary is textual and includes information about: The layers and their order in the model.\n",
    "model.summary()\n",
    "\n",
    "# train our model to get all the paramters to the correct value so that we can map our inputs to our outputs.\n",
    "history = model.fit_generator(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size,\n",
    "    callbacks=[tensorboard]\n",
    ")\n",
    "\n",
    "# save our model\n",
    "model.save(\"Models/\" + model_nom + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our model\n",
    "model.save(\"Models/\" + model_nom + \".h5\")\n",
    "\n",
    "# create a csv file to write report \n",
    "# (Timte, Model, Epochs, Batch Size, Number Classes, Avg Accuracy, Loss, Optimizer, Dropout, Learning Rate)\n",
    "# This conditions to deal with the problem of 'acc' and 'accuracy' in different environements\n",
    "with open('report.csv', 'a') as reportFile:\n",
    "    if 'acc' in history.history:                     \n",
    "        my_accuracy = history.history['acc'][0]\n",
    "    if 'accuracy' in history.history:\n",
    "        my_accuracy = history.history['accuracy'][0]\n",
    "\n",
    "    if ('accuracy' in history.history) or ('acc' in history.history):\n",
    "        x = datetime.datetime.now()\n",
    "        info = [x, model_nom, epochs, batch_size, units2,\n",
    "                my_accuracy, history.history['loss'][0], optimizer, dropout1, dropout2, learningrate]\n",
    "        writer = csv.writer(reportFile, delimiter=',', lineterminator='\\n')\n",
    "        writer.writerow(info)\n",
    "    else:\n",
    "        print(\"Couldn't save the report!!\")\n",
    "    \n",
    "    print(my_accuracy)  # Will help us in the K-fold cv script (K-fold.sh)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}